So let's talk about education in Eureka and stuff.
One thing you could do is start another AI lab and then try to solve those problems.
Yeah, you're curious what you up to now.
Yeah.
And then yeah, why not AI research itself?
I guess maybe like the way I would put it is I feel some amount of like determinism around the things that AI labs are doing.
And I feel like I could help out there, but I don't know that I would like uniquely, I don't know that I would like uniquely improve it.
But I think like my personal big fear is that a lot of the stuff happens on the side of humanity and that humanity gets disempowered by it.
And I kind of like I care not just about all the licensed fears that we're going to build and that AI is going to build in a fully autonomous way.
I care about what happens to humans and I want humans to be well off in this future.
And I feel like that's where I can lot more uniquely at value than like an incremental improvement in the frontier lab.
And so I guess I'm most afraid of something maybe like the picture in movies like Wally or idiocracy or something like that where humanity sort of on a side of this stuff.
And I want humans to be much, much better in this future.
And so I guess to me, this is kind of like through education that you can actually achieve this.
And so what are you working on there?
So Eureka is trying to build, I think maybe the easiest way I can describe it is we're trying to build the Starfleet Academy.
I don't know if you watch Star Trek.
I haven't.
Starfleet Academy is this like elite institution for frontier technology building spaceships and graduating cadets to be like in the piles of these spaces.
So I just imagine like in the elite institution for technical knowledge and and basically a kind of school that's very up to date and very like a premier institution.
A category of questions I have for you is just explaining how one teaches technical or scientific content.
Well, because you are one of the world masters at it.
And then I'm curious both about how you think about it for content you already put out there on YouTube.
Yeah, but also to the extent is any different how do you think about it for you?
Yeah, well, the respect to Eureka, I think like one thing that is very fascinating to me about education is like I do think education will pretty fundamentally change with a ice on the side.
And I think it has to be rewired and changed to some extent.
I still think that we're pretty early.
I think there's going to be a lot of people who are going to try to do the obvious things which is like, oh, have an LLM and ask it questions and get, you know, do all the basic things that you would do via prompting right now.
I think it's helpful, but it still feels to me a bit like slop, like slop.
I would like to do it properly and I think the capability is not there for what I would want.
What I'd want is like an actual tutor experience.
Maybe a prominent example in my mind is I was recently learning Korean so I'm just learning.
And I went through a phase where I was learning Korean by myself on the internet.
I went through a phase where I was actually part of a small class in Korea, taking a Korean with a bunch of other people which was really funny.
But we had a teacher and like 10 people are so taking Korean.
And then I switched to a 101 tutor.
And I guess what was fascinating to me is I think I had a really good tutor.
But I mean, just thinking through like what this tutor was doing for me and how incredible that experience was and how high the bar is for like what I actually want to build eventually.
Because I mean, she was extremely, so she instantly from a very short conversation understood like where I am as a student, what I know and don't know.
And she was able to like probe exactly like the kinds of questions or things to understand my world model.
No LLM will do that for you 100% right now, not even close, right.
But a tutor will do that if they're good.
Once she understands, she actually like really served me all the things that I needed at my current sliver of capability.
I need to be always appropriately challenged. I can't be faced with something too hard or too trivial.
And a tutor is really good at serving you just the right stuff.
And so basically I felt like I was the only constraint to learning like my own.
I was the only constraint. I was always given the perfect information.
I'm the only constraint.
And I felt good because I'm the only impediment that exists.
It's not that I can't find knowledge or there's not properly explained or etc.
Like it's just my ability to memorize and so on.
And this is what I want for people.
How do you automate that?
So very good question at the current capability you don't.
But I do think that with as and that's why I think it's not actually the right right time to actually build this kind of an AI tutor.
I still think it's a useful product and lots of people will build it.
But I still feel like the bar is so high and the capability is not there.
But I mean, even today I would say charge between is an extremely valuable educational product.
But I think for me was so fascinating to see how high the bar is.
And when I was with her, I almost felt like there's no way I can build this.
But you're building it right?
Anyone who's had a really good tutor is like, how are you going to build this?
So I guess I just I'm waiting for that capability.
I do think that in a lot of ways in the industry, for example, I did some AI consulting for computer vision.
A lot of my times the value that I brought to the company was telling them not to use AI.
It wasn't like I was the AI expert and they described the problem.
I said, don't use AI.
This was my value.
And I feel like it's the same in education right now where I kind of feel like
for what I have in mind, it's not yet the time, but the time will come.
And for now, I'm building something that looks maybe a bit more conventional.
That has a physical and digital component and so on.
But I think there's obvious, there's obvious it's obvious how this should look like in the future.
Do this and you're willing to say, what is the thing you hope will be released this year or next year?
Well, so I'm building the first course and I want to have a really, really good course.
State of the art, obvious state of the art destination you go to learn AI in this case, because that's just what I'm familiar with.
So I think it's a really good first product to get to be really good.
And so that's what I'm building and Nanachat, which you briefly mentioned,
is a capstone project of LLM111N, which is a class that I'm building.
So that's a really big piece of it, but now I have to build out a lot of the intermediates
and then I have to actually like hire a small team of, you know, TAs and so on,
actually like build the entire course.
And maybe one more thing that I would say is like many times when people think about education,
they think about sort of like the more what I would say is like kind of a softer component of like defusing knowledge or like.
But I actually have something very hard and technical in mind.
And so in my mind, education is kind of like the very difficult technical like process of building ramps to knowledge.
So in my mind Nanachat is a ramp to knowledge because it's a very simple.
It's like the super simplified full stack thing.
If you give this artifact to someone and they like look through it, they're learning a ton of stuff.
And so it's giving you a lot of what I call Eureka's per second, which is like understanding per second.
That's what I want. Lots of Eureka's per second.
And so to me, this is a technical problem of how do we build these ramps to knowledge?
And so I almost think of Eureka as almost like a it's not like maybe that different maybe through some of the future from tier labs or some of the work that's going to be going on because I want to figure out how to build these frontier.
These ramps very efficiently so that people are never stuck.
And everything is always not too hard or not too trivial.
And you can you have just the right material to actually progress.
Yeah, so you're imagining this short term that instead of a tutor being able to like probe your understanding.
If you have enough self awareness to be able to probe yourself, you're never going to be stuck.
You can like find the right answer between talking to the TA or talking to an L and looking at the reference implementation.
It sounds like the automation or AI is actually not as significant.
Like so far, it's actually the big off I hear is your ability to explain AI.
You're hardified in the source material of the class, right?
That's like fundamentally what the course is.
I mean, I think you always have to be calibrated to what the capability what capability is in the industry.
And I think a lot of people are going to pursue like, oh, just ask, charge of PT, etc.
But I think like right now, for example, if you go to charge between you say, oh, teach me AI.
There's no way it's like I'm just going to give you some slop, right?
Like when AI is never going to ride Nana chat right now, but Nana chat is a really useful, I think, intermediate point.
So I still, I'm collaborating with AI to create all this material.
So AI is still fundamentally very helpful.
Earlier on, I built a CS231N as Stanford, which was one of the earlier, actually, sorry, I think it was the first deep learning class as Stanford, which became very popular.
And the difference in building out to 31N and L101N now is quite stark.
Not because I feel really empowered by the elements as they exist right now, but I'm very much in the loop.
So they're helping me build the materials, I go much faster.
They're doing a lot of boring stuff, etc.
So I feel like I'm developing the course much faster and those LLM, if used in it, but it's not yet at a place where I can creatively create the content.
I'm still there to do that.
So like, I think the trickiness is always calibrating yourself to what exists.
And so when you imagine what is available through URICA in a couple of years,
it seems like the big bottleneck is going to be finding hypotheses and field after field who can
convert their understanding into these realms, right?
So I think it would change over time.
So I think right now, it would be hiring faculty to help work hand in hand with AI and a team of people probably to build a state of the art courses.
And then I think over time, it can maybe some of the TAs can actually become AI's because some of the TAs like,
okay, you just take all the course materials and then I think you could serve a very good like automated TA for the student when they have more basic questions or something like that, right?
But I think you'll need faculty for the overall architecture of course and making sure that it fits.
And so I kind of see a progression of how this will evolve.
And maybe at some future point, you know, I'm not even that useful in AI is doing most of the design much better than I could.
But I still think that that's going to take some time to play out.
But are you imagining that like people who have expertise in other fields are then contributing courses or do you feel like it's actually quite essential to the vision that you given your understanding of how you want to teach are the one designing the content.
Like I don't know, Sal Khan is like narrating all the videos of Khan Academy.
Are you imagining something like that or?
Oh, no, I will hire faculty. I think because there are domains in which I'm not an expert.
And I think that's the only way to offer the state of the art experience for the student ultimately.
So yeah, I do expect that I would hire faculty, but I will probably stick around in AI for some time.
But I do have something I think more conventional in mind for the current capability.
I think that what people would probably anticipate.
And when I'm building Starfleet Academy, I do probably imagine a physical institution and maybe a tear below that a digital offering that is not the state and not the state of the art experience.
You would get when someone comes in physically full time and we work through material from start to end and make sure you understand it.
That's the physical offering.
The digital offering is a bunch of stuff on the internet to maybe some element assistant and some bit more gimmicky and a tear below, but at least it's accessible to like eight billion people.
Yeah, I think you're basically inventing college from first principles for the tools that are available today.
And then just like for just like selecting for people who have the motivation and the interest of actually really engaging out material.
Yeah, and I think there's going to have to be a lot of not just education, but also reeducation.
And I would love to help out there because I think the job will probably change quite a bit.
And so for example, today a lot of people are trying to up skill in AI specifically.
So I think it's a really good course to teach in this in this respect.
And yeah, I think the motivation wise before AGI motivation is very simple to solve because people want to make money.
And this is how you make money in history today.
I think post AGI is a lot more interesting, possibly because yeah, if everything is automated and there's nothing to do for anyone, why would anyone go to a school, etc.
So I think I guess like I often say that pre AGI education is useful post AGI education is fun.
And in a similar way as people, for example, people go to gym today, but we don't need their physical strength to manipulate heavy objects because we have machines to do that.
So they still go to gym. Why do they go to gym? Well, because it's fun. It's healthy. It's and it's and you look hot when you have a six back. I don't know.
I guess like so it's I guess what I'm saying is it's attractive for people to do that is in a certain like very deep psychological evolutionary sense for humanity.
And so I kind of think that education will kind of play out in the same way like you'll go to school, like you go to gym.
And you'll and I think that right now I think not that many people learn because learning is hard.
You bounce from material because and some people overcome that barrier, but for most people, it's hard.
But I do think that we should it's a technical problem to solve. It's a technical problem to do what my tutor did for me when I was learning Korean.
I think it's tractable and buildable and so much to build it. And I think it's going to make learning anything like trivial and desirable and people will do it for fun because it's trivial.
If I had a tutor like that for any arbitrary piece of like knowledge, I think it's going to be so much easier to to learn anything and people will do it.
And they'll do it for the same reason they go to gym. I mean, that sounds different from using this supposed AGI you're using this to basically as entertainment or
as like a self-betterment, but it's down to like you had a vision also that this education is relevant to keeping humanity in control of AI.
I see.
And they sound different and I'm curious is it like it's entertaining for some people but then empowerment for some others? How do you think about that?
I think this so I do definitely feel like people will be I do think like eventually it's a bit of a losing game.
If that makes sense, I do think that it is in long term.
Yeah, long term, which I think put is longer than I think maybe most people in the history. It's a losing game.
I do think that people can go so far and that we barely scratch the surface of much person can go.
And that's just because people are bouncing off of material that's too easy or too hard.
And I actually kind of feel that people will be able to go much further like anyone speaks five languages because why not?
Because it's so trivial.
Anyone knows, you know, all the basic curriculum of hundreds and etc.
Now that I'm understanding the vision.
That's very interesting like I think it actually has a perfect analog in gym culture.
I don't think a hundred years ago anybody would be like ripped like nobody would have you know be able to like just spontaneously bench to play certain three plays or something.
It's actually very common now.
And you're because this idea of systematically training and lifting weights in the gym or systematically training to be able to run a marathon.
Which is capability spontaneously you would not have or most humans would not have.
And you're imagining similar things were.
Learning across very many different domains were intensely deeply faster.
Yeah, exactly. And I kind of feel like I am betting a little bit implicitly on some of the timelessness of human nature.
And I think I think it will be desirable to be.
To do all these things.
And I think people look up to it and as they have for for millennia because.
And I think this will continue to be true.
And actually also maybe there's some evidence of that historically because if you look at for example aristocrats or you look at maybe ancient Greece or something like that.
Whenever you had little pocket environments that were post a GI in a certain sense.
I do feel like people have spent a lot of their time flourishing in a certain way.
Either physically or comfortably.
And so I think I feel okay about the prospects of that.
And I think if this is false and I'm wrong and we end up in like you know.
Wally or idiocracy future then I think it's very I don't even care.
There's like Dyson spheres.
This is terrible outcome.
Yeah, like I actually really do care about humanity.
Like everyone has to just be superhuman in the circumstances.
I guess it's still a world in which that is not enabling us to.
It's like the culture world where like you're not fundamentally going to be able to like transform the trajectory of.
Yeah, technology or.
Yeah, influence decisions by your own labor or cognition alone.
Maybe you can influence decisions because the AI is like for approval.
But you're not like it's not because I have like I can because I've invented something or I like come up with a new design.
I'm like really influencing the future.
Yeah, maybe I don't actually think that I think there will be transition in a period where we are going to be able to be in the loop and.
You know the advanced things if we actually understand a lot of stuff.
I do think that long term that probably goes away, right?
But maybe it's going to even come a sport.
But right now you have power lifters who go extreme on this ration.
So what is power lifting in a cognitive era?
Maybe it's people who are really trying to make Olympics out of knowing stuff.
Like and and if you have a perfect AI tutor, maybe you can get extremely far.
I must feel like we're just barely the geniuses of today.
I bear discussion to surface of what a human mind can do, I think.
Yeah, I love this version.
I also it's like I feel like the person who have like most product market fit with is like me because like my job involves having to learn different subjects every week.
And I am I am like very excited if you can.
I'm similar for that matter.
I mean, I you know a lot of people for example, hate school.
I want to get out of it.
I was actually I really liked school.
I love learning things, etc.
I wanted to stay in school.
I stayed all the way until PhD and then they wouldn't let me stay longer.
So I went to the industry.
But I mean, I basically it's roughly speaking.
I love I love learning even for the sake of learning.
But I also love learning because it's form of empowerment and being useful and productive.
I think you also made a point that we started also just to spell it out.
I think what's happened so far with online courses is that why haven't they already enabled us to
enable everything with you meant to know everything.
And I think they're just so motivation laden because there's not obvious on ramps.
And it's like so easy to get stuck.
And if you had instead this this thing, basically like a really good human tutor.
It would just be such an unlike from a motivation perspective.
I think so.
Yeah, because it feels bad to bounce from material.
It feels bad.
You get negative reward from a sinking amount of time and something and doesn't
pen out or like being completely bored because what you're getting is too easy or too hard.
So I think, yeah, I think it feel when you actually do it properly, learning feels good.
Yeah.
And I think it's technical problem to get there.
And I think for a while, it's going to be AI plus human collab.
And at some point, maybe it's just AI.
Can I ask some questions about teaching?
Well, if you had to like sort of like give advice to another educator in another field
that you're curious about to make the kinds of YouTube tutorials you've made.
Maybe it may be especially interesting to talk about domains where you can't just like
you can't test somebody's technical understanding by having them code something up or something.
What advice would you give them?
So I think that's a pretty broad topic.
I do feel like there's basically, I almost feel like there are 10, 20 tips and tricks that I kind
of semi consciously probably do.
But I guess like on a high level, I always try to, I think a lot of this comes
from my physics background.
I really, really did enjoy my physics background.
I have a whole rant when I think how everyone should learn physics in the in early school education.
Because I think early school education is not about
a criminal knowledge or memory for tasks later in the industry.
It's about booting up a brain.
And I think physics uniquely boots up the brain the best because some of the things that
they get you to do in your brain during physics is extremely valuable later.
The idea of building models and abstractions and understanding that there are,
there's a first order of approximation that describes most of the system.
But then there's a second order, third order, first order terms that may or may not be present.
And the idea that you're observing like a very noisy system,
but actually there's like these fundamental frequencies that you can abstract away.
Like when a physicist walks into the class and they say,
oh, assuming there's a spherical cow and dot, dot, dot.
And everyone laughs at that, but actually this brilliant, brilliant thinking
that's very journalizable across the industry because, yeah, cow is,
can be approximate as a sphere, I guess, in a bunch of ways.
There's a really good book, for example, scale.
It's basically from a physicist talking about biology.
And maybe this is also a book I've been reading, but you can actually get a lot
of really interesting approximations and chart scaling loss of animals.
And you can get their heartbeats and things like that.
And they actually line up and with the size of the animal and things like that.
You can talk about an animal as a volume and you can actually drive a lot of,
you can talk about the heat dissipation off that because your,
your heat dissipation grows as the surface area, which is growing a square,
but your heat creation or generation is growing as a cube.
And so I just feel like physicists have all the right cognitive tools
to approach Brown and solving in the world.
So I think because of that training, I always try to find the first order terms,
or the second order terms of everything.
When I'm observing a system or a thing, I have a tangle of a web of ideas
or knowledge in my world, in my mind.
And I'm trying to find what is the, what is the thing that actually matters?
What is the first order component?
How can I simplify it?
How can I have a simple thing that actually shows that thing?
It shows a, it shows an action.
And then I can tackle in the other terms.
Yeah, maybe, maybe an example from my, from one of my repos that I think
illustrates it well is called micrograd.
I don't know if you're familiar with this, but.
So micrograd is 100 lines of code that shows back propagation.
It can, you can create neural networks out of simple operations,
like plus and times, et cetera, Lego blocks of neural networks.
And you build up a computational graph and you do a forward pass
and a backward pass to get the gradients.
Now, this is at the heart of all neural network learning.
So micrograd is a 100 lines of pretty interpretable Python code.
And it can do forward and backward arbitrary neural networks,
but not efficiently.
So micrograd, these 100 lines of Python are everything you need to understand
how neural networks train.
Everything else is just efficiency.
Yeah, everything else is efficiency.
And there's a huge amount of work to do efficiency.
You know, you need your tensors, you lay them out, you stride them,
you make sure your kernels are orchestrating memory movement,
correctly, et cetera.
It's all just efficiency, roughly speaking.
But the core intellectual sort of piece of neural network training is micrograd.
It's 100 lines, you can easily understand it.
You're changing, it's recursive application of chain rule to drive the gradient,
which allows you to optimize any arbitrary differential function.
So it's a, I love finding these like, you know, the smaller the terms
and serving them on the platter and discovering them.
And I feel like education is like the most intellectual, interesting thing
because you have a tangle of understanding and you're trying to lay it out
in a way that creates a ramp where everything only depends on the thing before it.
And I find that this like, you know, untangling of knowledge
is just so intellectually interesting as a cognitive task.
Yeah.
And so I love doing it personally, but I just find I have a fascination
with trying to lay things out in a certain way.
Maybe that helps me.
It also just makes a learning experience so much more motivated.
Your tutorial on the transformer begins with bigrams,
literally like a lookup table from here is the word right now,
or here's the previous word, here's the next word,
and it's literally just a lookup table.
Yes, the essence of it, yeah.
I mean, such a brilliant way, like, okay, start with the lookup table
and then go to a transformer and each piece is motivated.
Why would you add that?
Why would you add the next thing?
You couldn't memorize the sort of attention for me, love,
just like having an understanding of why this is every single piece is relevant.
What a problem it solves.
Yeah, yeah, yeah, you're presenting the pain before we present a solution.
And how clever is that?
And you want to take the student through that progression.
So there's a lot of like other small things like that
that I think make it make it nice and engaging and interesting.
And always prompting the student, there's a lot of small things like that.
I think are important and a lot of good educators will do.
Like, how would you solve this?
Like, I'm not going to present a solution before you're going to guess.
That would be wasteful.
That's a little bit of a, I don't want to swear.
But like it's a it's a dick move towards you to present you with the solution
before I give you a shot to try to come up with it yourself.
Because if you try to come with yourself,
I guess you get a better understanding of like
what is the action space?
Yeah.
And then what is the sort of like objective?
Then like why does only this action fulfill that objective?
Yeah.
Well, you have a chance to like try yourself and you've you've given appreciation
when I give you the solution.
And you maximize the amount of knowledge per you fact added.
That's right.
Why do you think by default people who are genuine experts in their field
are often bad at explaining it to somebody ramping up.
Well, it's the curse of knowledge and expertise.
Yeah, this is a real phenomenon.
I actually suffered from it myself as much as I tried to not not suffer from it.
But you take certain things for granted and you can't be sure
something issues of new of people who are just starting out.
And this is pervasive and happens to me as well.
One thing that I actually think is extremely helpful as an example.
Someone was trying to show me a paper in biology recently.
And I just had instantly so many terrible questions.
So what I did was I used chat GPT to ask the questions with the paper in the context window.
And then it worked through some of the simple things.
And then I actually shared the thread to the person who shared it,
who actually like wrote that paper, like worked on that work.
And I almost feel like it was like,
like if they can see the dumb questions I had,
it might help them explain better in the future and stuff like that.
Because so for example, for my material, I would love if people
shared their dumb conversations with chat GPT about the stuff that I've created
because it really helps me put myself again in the shoes of someone who's starting out.
Another trick like that that I just works astoundingly well.
If somebody writes a paper or a blog post or an announcement,
it is in a 100% of cases true that just the narration or the transcription
of how they would explain it to you over lunch is way more,
not only understandable, but actually also more accurate and scientific
in the sense that people have a bias to explain things in the most abstract,
jargon-filled way possible and to clear their throat for four paragraphs
before they explain the central idea.
But there's something about communicating one on one with a person
which compels you to just say the thing.
Just say the thing.
Actually, I saw that tweet. I thought it was really good.
I shared it with a bunch of people actually.
I think it was really good.
And I noticed this many, many times.
Maybe the most prominent example is I remember back in my PhD days doing research,
et cetera, you read someone's paper, right?
And you work to understand what is doing, et cetera.
And then you catch them.
You're having beers at the conference later and you asked them
so like this paper, like so what are you doing?
Like what is the paper about?
And they will just tell you these like three sentences that like perfectly
captured the essence of that paper and told to give you the idea
and you didn't have to read the paper.
And like it's only when you're sitting at the table with a beer or something like that
and like, oh, yeah, the paper is just, oh, you take this idea.
You take that idea and try this experiment and you try this thing.
And they have a way of just putting it conversationally,
and just like perfectly like, why isn't that the answer?
Exactly.
This is coming from the perspective of how somebody who's trying to explain
an idea should formulate it better.
What is your advice as a student to other students where
if you don't have a carpathy who is doing the exposition of an idea,
if you're reading a paper from somebody or reading a book,
what strategies do you employ to learn material you're interested in
in fields you're not an expert in?
I don't actually know that I have like unique tips and tricks to be honest.
Basically, it's kind of a painful process, but you know, like redraft one.
I think like one thing that has always helped me quite a bit is
I had a small tweet about this actually, so like learning things on demand
is pretty nice, learning depth wise.
I do feel like you need a bit of alternation of learning depth wise on demand.
You're trying to achieve a certain project that you're going to get a reward from
and learning breadth wise, which is just, oh, let's do whatever 101
and here's all the things you might need, which is a lot of school.
There's a lot of breadth wise learning.
Oh, trust me, you'll need this later, you know, that kind of a stuff.
Like, okay, I trust you, I'll learn it because I guess I need it.
But I love the kind of learning where you actually get a reward
of doing something and you're learning on demand.
The other thing that I've found is extremely helpful is
maybe this is an aspect where education is a bit more selfless
because explaining things to people is a beautiful way to learn something more deeply.
This happens to me all the time.
I think it probably happens to other people too because
I realize if I don't really understand something, I can't explain it, you know,
and I'm trying and I'm like, actually, I don't understand this.
And so knowing to come to terms with that and then you can go back and make sure you
understood it.
And so it fills these gaps of your understanding.
It forces you to come to terms with them and to reconcile them.
I love to re-explain and things like that.
And I think people should be doing that more as well.
I think that forces you to manipulate the knowledge and make sure that you,
you know, what you're talking about when you're explaining it.
I think that's an excellent note to close on.
Yeah.
Andre, that was great.
Yeah, thank you.
Thanks.
Hey, everybody.
I hope you enjoyed that episode.
If you did, the most helpful thing you can do is just share it with
other people who you think might enjoy it.
It's also helpful if you leave a rating or comment on whatever platform
you're listening on.
If you're interested in sponsoring the podcast, you're going to reach out
at thewarkesh.com slash advertise.
Otherwise, I'll see you at the next one.
